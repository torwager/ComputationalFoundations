{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c71d09",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a63bbe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.026063Z",
     "start_time": "2023-09-28T18:49:52.530968Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/f003vz1/Library/Python/3.8/lib/python/site-packages/davos/core/project.py:896: UserWarning: Failed to identify notebook path. Falling back to generic default project\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import davos\n",
    "except ModuleNotFoundError:\n",
    "    %pip install davos\n",
    "    import davos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf60c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.515315Z",
     "start_time": "2023-09-28T18:49:53.027815Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.26.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0rc1, 1.23.0rc2, 1.23.0rc3, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0rc1, 1.24.0rc2, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\u001b[0m\r\n",
      "\u001b[31mERROR: No matching distribution found for numpy==1.26.0\u001b[0m\r\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 23.3.1 is available.\r\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    },
    {
     "ename": "InstallerError",
     "evalue": "Command 'PYTHONUSERBASE=\"/Users/f003vz1/.davos/projects/davos-fallback\" /Users/f003vz1/Library/Python/3.8/bin/pip install --no-warn-script-location --user numpy==1.26.0' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/core/core.py:675\u001b[0m, in \u001b[0;36mOnion._pip_install_package\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 675\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[43mrun_shell_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/core/core.py:936\u001b[0m, in \u001b[0;36mrun_shell_command\u001b[0;34m(command, live_stdout)\u001b[0m\n\u001b[1;32m    935\u001b[0m         e\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m stdout\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    937\u001b[0m stdout \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/core/core.py:929\u001b[0m, in \u001b[0;36mrun_shell_command\u001b[0;34m(command, live_stdout)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 929\u001b[0m     \u001b[43m_run_shell_command_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;66;03m# if the exception doesn't record the output, add it\u001b[39;00m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;66;03m# manually before raising\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/implementations/ipython_common.py:111\u001b[0m, in \u001b[0;36m_run_shell_command_helper\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(returncode\u001b[38;5;241m=\u001b[39mretcode, cmd\u001b[38;5;241m=\u001b[39mcommand)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'PYTHONUSERBASE=\"/Users/f003vz1/.davos/projects/davos-fallback\" /Users/f003vz1/Library/Python/3.8/bin/pip install --no-warn-script-location --user numpy==1.26.0' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInstallerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m smuggle(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollections.abc.Iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43msmuggle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnumpy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstaller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mnumpy==1.26.0\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstaller_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meditable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumpy==1.26.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m smuggle(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpd\u001b[39m\u001b[38;5;124m\"\u001b[39m, installer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, args_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mpandas==2.1.1\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, installer_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meditable\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas==2.1.1\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      5\u001b[0m smuggle(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscipy.stats\u001b[39m\u001b[38;5;124m\"\u001b[39m, as_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m, installer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m\"\u001b[39m, args_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mscipy==1.11.2\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, installer_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meditable\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspec\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy==1.11.2\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/core/core.py:979\u001b[0m, in \u001b[0;36muse_project.<locals>.smuggle_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m importlib\u001b[38;5;241m.\u001b[39minvalidate_caches()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msmuggle_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# after (possibly installing and) loading the package,\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;66;03m# remove the project's site-packages directory from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;66;03m# other dirs being prepended to load modules installed\u001b[39;00m\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# in custom locations\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mstr\u001b[39m(project\u001b[38;5;241m.\u001b[39msite_packages_dir))\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/core/core.py:1077\u001b[0m, in \u001b[0;36msmuggle\u001b[0;34m(name, as_, installer, args_str, installer_kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m confirmed:\n\u001b[1;32m   1074\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SmugglerError(\n\u001b[1;32m   1075\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1076\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1077\u001b[0m installer_stdout \u001b[38;5;241m=\u001b[39m \u001b[43monion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstall_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;66;03m# invalidate sys.meta_path module finder caches. Forces import\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;66;03m# machinery to notice newly installed module\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m importlib\u001b[38;5;241m.\u001b[39minvalidate_caches()\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/davos/core/core.py:677\u001b[0m, in \u001b[0;36mOnion._pip_install_package\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m run_shell_command(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstall_cmd)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstallerError\u001b[38;5;241m.\u001b[39mfrom_error(e)\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# handle packages installed in non-standard locations\u001b[39;00m\n\u001b[1;32m    679\u001b[0m install_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstaller_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mInstallerError\u001b[0m: Command 'PYTHONUSERBASE=\"/Users/f003vz1/.davos/projects/davos-fallback\" /Users/f003vz1/Library/Python/3.8/bin/pip install --no-warn-script-location --user numpy==1.26.0' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "from collections.abc smuggle Iterable\n",
    "\n",
    "smuggle numpy as np                 # pip: numpy==1.26.0\n",
    "smuggle pandas as pd                # pip: pandas==2.1.1\n",
    "from scipy smuggle stats            # pip: scipy==1.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd935da",
   "metadata": {},
   "source": [
    "# Implement a GLM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ef5730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.518531Z",
     "start_time": "2023-09-28T18:49:53.516512Z"
    }
   },
   "outputs": [],
   "source": [
    "def requires_fit(method):\n",
    "    \"\"\"\n",
    "    Decorator used in GLM class to disallow running certain methods \n",
    "    before fitting the model.\n",
    "    \"\"\"\n",
    "    def check_fitted_wrapper(self, *args, **kwargs):\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\n",
    "                f\"Model must be fit before running self.{method.__name__}. \"\n",
    "                \"Fit the model first with self.fit()\"\n",
    "            )\n",
    "        return method(self, *args, **kwargs)\n",
    "    return check_fitted_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7347625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.555282Z",
     "start_time": "2023-09-28T18:49:53.519870Z"
    }
   },
   "outputs": [],
   "source": [
    "class GLM:\n",
    "    def __init__(self, X, y, ensure_intercept=True, predictor_labels=None):\n",
    "        \"\"\"\n",
    "        Initialize a GLM instance to fit, inspect, and run tests.\n",
    "        Accepts a design matrix X and response vector y as lists/numpy\n",
    "        arrays or labeled pandas DataFrames/Series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Design matrix with shape (n, p). `n` is the number of\n",
    "            observations and `p` is the number of predictors, optionally\n",
    "            including an intercept (see `ensure_intercept` below).\n",
    "            If X is a pandas DataFrame, column names will be used as\n",
    "            labels for the predictor variables.\n",
    "        y : array-like\n",
    "            Response vector with shape (n,).\n",
    "        ensure_intercept : bool, optional\n",
    "            If True (default), ensure that the first column of X\n",
    "            contains all 1's for the intercept, inserting one if\n",
    "            necessary. If False, do not include an intercept.\n",
    "        predictor_labels : list of str, optional\n",
    "            List of labels for the predictors in X. If None (default),\n",
    "            use column names from X if X is a pandas DataFrame,\n",
    "            otherwise use generic labels \"X_0\", \"X_1\", etc.\n",
    "        \"\"\"\n",
    "        if predictor_labels is None:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                self.predictor_labels = X.columns.tolist()\n",
    "            elif isinstance(X, pd.Series):\n",
    "                self.predictor_labels = X.index.tolist()\n",
    "            else:\n",
    "                self.predictor_labels = [f\"X_{i}\" for i in range(X.shape[1])]\n",
    "        elif not isinstance(predictor_labels, Iterable):\n",
    "            raise TypeError(\"'predictor_labels' must be an iterable if passed\")\n",
    "        elif len(predictor_labels) != X.shape[1]:\n",
    "            raise ValueError(\n",
    "                f\"'predictor_labels' must contain {X.shape[1]} labels\"\n",
    "            )\n",
    "        else:\n",
    "            self.predictor_labels = predictor_labels\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y).squeeze()\n",
    "\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\n",
    "                \"X and y must have the same number of rows (observations)\"\n",
    "            )\n",
    "        if y.ndim != 1:\n",
    "            raise ValueError(\"y must be a n x 1 vector of observed responses\")\n",
    "\n",
    "        if ensure_intercept and not (X[:, 0] == 1).all():\n",
    "            self.X_ = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "            self.predictor_labels.insert(0, \"Intercept\")\n",
    "        else:\n",
    "            self.X_ = X\n",
    "\n",
    "        self.y_ = y\n",
    "        self.n_obs = X.shape[0]\n",
    "        self.n_predictors = self.X_.shape[1]    # p includes intercept\n",
    "        self.df_model = self.n_predictors - 1\n",
    "        self.df_error = self.n_obs - self.n_predictors\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit the model with the data provided at initialization. Both\n",
    "        returns the fitted model and updates it in place (a la\n",
    "        scikit-learn estimators).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        GLM\n",
    "            The fitted GLM instance\n",
    "        \"\"\"\n",
    "        gram_inv = np.linalg.inv(self.X_.T @ self.X_)\n",
    "        # beta-hat, shape: (self.n_predictors,)\n",
    "        self.betas = gram_inv @ self.X_.T @ self.y_\n",
    "        # y-hat, shape: (self.n_obs,)\n",
    "        # also alias y_hat as y_pred (standard scikit-learn convention)\n",
    "        self.y_hat = self.y_pred = self.X_ @ self.betas\n",
    "        # residuals, shape: (self.n_obs,)\n",
    "        self.residuals = self.y_ - self.y_hat\n",
    "        self.ss_res = (self.residuals ** 2).sum()\n",
    "        self.ss_tot = ((self.y_ - self.y_.mean()) ** 2).sum()\n",
    "        self.R2 = 1 - self.ss_res / self.ss_tot\n",
    "        self.AIC = self.n_obs * np.log(self.ss_res / self.n_obs) + 2 * self.n_predictors\n",
    "        # variance/covariance matrix for betas,\n",
    "        # shape: (self.n_predictors, self.n_predictors)\n",
    "        self.beta_cov = self.ss_res / self.df_error * gram_inv\n",
    "        # standard errors for betas, shape: (self.n_predictors,)\n",
    "        self.beta_ses = np.diag(self.beta_cov) ** 0.5\n",
    "        # t-statistics for betas, shape: (self.n_predictors,)\n",
    "        self.beta_ts = self.betas / self.beta_ses\n",
    "        # (2-tailed) p-values for t-tests for betas,\n",
    "        # shape: (self.n_predictors,)\n",
    "        self.beta_ps = 2 * stats.t.sf(np.abs(self.beta_ts), self.df_error)\n",
    "        # set fitted flag to True to enable other methods that require\n",
    "        # these computations first\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    @requires_fit\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the value of the response variable for new data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Array containing with the same number of predictors as the\n",
    "            design matrix used to fit the model. May contain any number\n",
    "            of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : 1D array\n",
    "            Predicted values of the response variable for each row of X.\n",
    "\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(np.asarray(X))\n",
    "        if X.shape[1] != self.n_predictors:\n",
    "            raise ValueError(\n",
    "                f\"X must have {self.n_predictors} columns (predictors)\"\n",
    "            )\n",
    "        return X @ self.betas\n",
    "\n",
    "    @requires_fit\n",
    "    def summary(self):\n",
    "        \"\"\"Print a formatted summary table of model results.\"\"\"\n",
    "        print(\"General Linear Model\")\n",
    "        print(\"===================\")\n",
    "        print(f\"Number of observations: {self.n_obs}\")\n",
    "        print(f\"Number of predictors: {self.n_predictors}\")\n",
    "        print(f\"Model degrees of freedom: {self.df_model}\")\n",
    "        print(f\"Error degrees of freedom: {self.df_error}\")\n",
    "        print(f\"Residual standard error: {self.ss_res:.3f}\")\n",
    "        print(f\"R^2: {self.R2:.3f}\")\n",
    "        print(f\"AIC: {self.AIC:.3f}\")\n",
    "        print(\"\\nCoefficients:\")\n",
    "        print(\"-------------\")\n",
    "        # Format the table width to fit the longest predictor name\n",
    "        # (min width: 4 cols)\n",
    "        name_col_width = max(len(max(self.predictor_labels, key=len)), 4)\n",
    "        header = \"\\033[1m{:<{width}}{:>8}{:>8}{:>8}{:>8}\\033[0m\".format(\n",
    "            \"Name\", \"B̂\", \"SE\", \"t\", \"p\", width=name_col_width\n",
    "        )\n",
    "        print(header)\n",
    "        for i in range(self.n_predictors):\n",
    "            label = self.predictor_labels[i]\n",
    "            beta = self.betas[i]\n",
    "            se = self.beta_ses[i]\n",
    "            t = self.beta_ts[i]\n",
    "            p = self.beta_ps[i]\n",
    "            if p < 0.001:\n",
    "                sig = '***'\n",
    "            elif p < 0.01:\n",
    "                sig = '**'\n",
    "            elif p < 0.05:\n",
    "                sig = '*'\n",
    "            else:\n",
    "                sig = ''\n",
    "            print(\"{:<{width}}{:>8.3f}{:>8.3f}{:>8.3f}{:>8.3f} \\033[1m{sig}\\033[0m\".format(\n",
    "                label, beta, se, t, p, width=name_col_width, sig=sig)\n",
    "            )\n",
    "\n",
    "    @requires_fit\n",
    "    def t_test(self, predictor):\n",
    "        \"\"\"\n",
    "        Two-tailed t-test for the null hypothesis that the estimated\n",
    "        coefficient for a given predictor is not significantly\n",
    "        different from zero.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictor : int or str\n",
    "            Index or label of predictor for which to run the t-test.\n",
    "            Note that the 0th predictor refers to the intercept.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t, p\n",
    "            t-statistic and associated p-value as a tuple.\n",
    "        \"\"\"\n",
    "        if isinstance(predictor, str):\n",
    "            predictor = self.predictor_labels.index(predictor)\n",
    "        elif not isinstance(predictor, int):\n",
    "            raise TypeError(\"'predictor' must be an int or str\")\n",
    "        return self.beta_ts[predictor], self.beta_ps[predictor]\n",
    "\n",
    "    @requires_fit\n",
    "    def test_contrast(self, contrast):\n",
    "        \"\"\"\n",
    "        Two-tailed t-test for the null hypothesis that the given\n",
    "        contrast of predictors is not significantly different from zero.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        contrast : array-like\n",
    "            Contrast vector of shape (p,). p is the number of predictors\n",
    "            (including the intercept).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t, p\n",
    "            t-statistic and associated p-value as a tuple.\n",
    "        \"\"\"\n",
    "        contrast = np.asarray(contrast).squeeze()\n",
    "        if contrast.ndim != 1:\n",
    "            raise ValueError(\"'contrast' must be a 1D array\")\n",
    "        if contrast.shape[0] != self.n_predictors:\n",
    "            raise ValueError(\n",
    "                f\"'contrast' must have {self.n_predictors} elements\"\n",
    "            )\n",
    "        # compute t-statistic\n",
    "        # note: contrast matrices not transposed here because numpy\n",
    "        # automatically does so for 1D vectors\n",
    "        t_stat = (\n",
    "                (contrast @ self.betas) /\n",
    "                np.sqrt(contrast @ self.beta_cov @ contrast)\n",
    "        )\n",
    "        # compute (2-tailed) p-value\n",
    "        p_value = 2 * stats.t.sf(np.abs(t_stat), self.df_error)\n",
    "        return t_stat, p_value\n",
    "\n",
    "    @requires_fit\n",
    "    def f_test(self, predictors=None):\n",
    "        \"\"\"\n",
    "        F-test for the null hypothesis that the given (set of)\n",
    "        predictor(s) has no effect on the response variable (i.e., that\n",
    "        the quality of the model fit would not significantly worsen if\n",
    "        the given predictor(s) were removed).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictors : int, str, or iterable of int or str, optional\n",
    "            index/indices or label(s) of predictor(s) for which to run\n",
    "            the F-test. Note that the 0th predictor refers to the\n",
    "            intercept. If None (default), the F-test is run on all\n",
    "            predictors (i.e., an intercept-only model).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        F, p: tuple of float\n",
    "            F-statistic and associated p-value as a tuple.\n",
    "        \"\"\"\n",
    "        if predictors is None:\n",
    "            predictors = predictors = list(range(1, self.n_predictors))\n",
    "        elif isinstance(predictors, int):\n",
    "            predictors = [predictors]\n",
    "        elif isinstance(predictors, str):\n",
    "            predictors = [self.predictor_labels.index(predictors)]\n",
    "        elif isinstance(predictors, Iterable):\n",
    "            _predictors = []\n",
    "            for p in predictors:\n",
    "                if isinstance(p, str):\n",
    "                    _predictors.append(self.predictor_labels.index(p))\n",
    "                elif isinstance(p, int):\n",
    "                    _predictors.append(p)\n",
    "                else:\n",
    "                    raise TypeError(\n",
    "                        \"'predictors' must be an int, str, or iterable of int \"\n",
    "                        \"or str\"\n",
    "                    )\n",
    "            predictors = _predictors\n",
    "        if not all(p in range(self.n_predictors) for p in predictors):\n",
    "            raise ValueError(\"'predictors' must be a valid predictor index or \"\n",
    "                             \"label\"\n",
    "                             )\n",
    "        if len(predictors) == 0:\n",
    "            raise ValueError(\"'predictors' must contain at least one index or \"\n",
    "                             \"label\"\n",
    "                             )\n",
    "        # get sum of squared residuals for reduced model\n",
    "        X_reduced = np.delete(self.X_, predictors, axis=1)\n",
    "        betas_reduced = np.linalg.inv(X_reduced.T @ X_reduced) @ X_reduced.T @ self.y_\n",
    "        residuals_reduced = self.y_ - X_reduced @ betas_reduced\n",
    "        ssr_reduced = (residuals_reduced ** 2).sum()\n",
    "        # compute F-statistic\n",
    "        ssr_full = self.ss_res\n",
    "        p = self.n_predictors\n",
    "        q = len(predictors)\n",
    "        n = self.n_obs\n",
    "        f_stat = ((ssr_reduced - ssr_full) / (p - q)) / (ssr_full / (n - p))\n",
    "        # compute p-value\n",
    "        p_value = stats.f.sf(f_stat, p - q, n - p)\n",
    "        return f_stat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b2435",
   "metadata": {},
   "source": [
    "# Load in (and clean) some data to test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927a48fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.798191Z",
     "start_time": "2023-09-28T18:49:53.556354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>exercise</th>\n",
       "      <th>handedness</th>\n",
       "      <th>sses</th>\n",
       "      <th>married_or_living_as_marri</th>\n",
       "      <th>...</th>\n",
       "      <th>sopa_emo_after</th>\n",
       "      <th>pgic</th>\n",
       "      <th>tx_satisfaction</th>\n",
       "      <th>alcohol_before</th>\n",
       "      <th>alcohol_after</th>\n",
       "      <th>opioid_before</th>\n",
       "      <th>opioid_after</th>\n",
       "      <th>cannabis_before</th>\n",
       "      <th>cannabis_after</th>\n",
       "      <th>bpi_intensity_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1268</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  group  education  ethnicity  hispanic  employment_status  exercise  \\\n",
       "0      12    3.0        2.0        4.0       0.0                1.0       3.0   \n",
       "1      14    3.0        3.0        4.0       0.0                3.0       4.0   \n",
       "2      15    3.0        2.0        5.0       0.0                1.0       3.0   \n",
       "3      18    2.0        3.0        4.0       0.0                1.0       3.0   \n",
       "4      23    2.0        3.0        2.0       0.0                1.0       5.0   \n",
       "..    ...    ...        ...        ...       ...                ...       ...   \n",
       "130  1268    2.0        3.0        4.0       0.0                2.0       4.0   \n",
       "131  1277    2.0        3.0        4.0       0.0                1.0       3.0   \n",
       "132  1294    2.0        3.0        4.0       0.0                1.0       3.0   \n",
       "133  1302    3.0        3.0        4.0       0.0                1.0       2.0   \n",
       "134  1319    2.0        3.0        5.0       0.0                1.0       3.0   \n",
       "\n",
       "     handedness  sses  married_or_living_as_marri  ...  sopa_emo_after  pgic  \\\n",
       "0           1.0   4.0                         0.0  ...             8.0   1.0   \n",
       "1           1.0   9.0                         0.0  ...             6.0   1.0   \n",
       "2           1.0   6.0                         1.0  ...             4.0   1.0   \n",
       "3           1.0   5.0                         1.0  ...             9.0   5.0   \n",
       "4           1.0   6.0                         0.0  ...             8.0   1.0   \n",
       "..          ...   ...                         ...  ...             ...   ...   \n",
       "130         1.0   8.0                         1.0  ...             8.0   5.0   \n",
       "131         1.0   8.0                         1.0  ...            10.0   5.0   \n",
       "132         1.0   6.0                         0.0  ...             8.0   2.0   \n",
       "133         1.0   8.0                         0.0  ...             6.0   2.0   \n",
       "134         1.0   5.0                         0.0  ...             5.0   5.0   \n",
       "\n",
       "     tx_satisfaction  alcohol_before  alcohol_after  opioid_before  \\\n",
       "0               52.0             0.0            0.0            0.0   \n",
       "1               30.5            23.0           21.0            0.0   \n",
       "2               50.5            15.0           29.0            0.0   \n",
       "3               50.0             0.0            2.0            0.0   \n",
       "4               17.5            29.0           13.5            0.0   \n",
       "..               ...             ...            ...            ...   \n",
       "130             88.0             2.0            1.0            0.0   \n",
       "131             46.0            23.0           30.0            0.0   \n",
       "132             54.0             0.0            0.0            0.0   \n",
       "133             64.0             3.0            3.0            0.0   \n",
       "134             69.0            11.0            3.0            2.0   \n",
       "\n",
       "     opioid_after  cannabis_before  cannabis_after  bpi_intensity_change  \n",
       "0             0.0            2.000           0.000                 -0.25  \n",
       "1             0.0            3.500           3.500                  0.50  \n",
       "2             0.0            0.000           0.000                 -0.50  \n",
       "3             0.0            0.000           0.000                  2.25  \n",
       "4             0.0            0.015           0.025                  0.25  \n",
       "..            ...              ...             ...                   ...  \n",
       "130           0.0            0.000           0.000                  1.75  \n",
       "131           0.0            0.000           0.000                 -0.75  \n",
       "132           0.0            0.000           0.000                  0.00  \n",
       "133           0.0            0.000           0.000                  0.00  \n",
       "134           1.0            7.000          19.000                  0.75  \n",
       "\n",
       "[135 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset from GitHub\n",
    "dataset_url = (\n",
    "    \"https://github.com/torwager/ComputationalFoundations/raw/\"\n",
    "    \"79b92a3/CompFound/datasets/Ashar2022_outcomes_demographics.csv\"\n",
    ")\n",
    "df_raw = pd.read_csv(dataset_url, na_values={'current_opioid_use': '<undefined>'})\n",
    "\n",
    "# drop individuals that don't have data for both sessions\n",
    "dupes_only = df_raw.loc[df_raw.duplicated('id', keep=False)]\n",
    "\n",
    "# make sure each individual's data actually comes from 2 different \n",
    "# sessions (i.e., no duplicates or mislabels)\n",
    "for i in dupes_only['id'].unique():\n",
    "    assert set(dupes_only.query('id == @i')['time']) == {1, 2}\n",
    "\n",
    "# reshape to have one row per participant with data from both sessions\n",
    "# pivot on columns with session-agnostic values (age, gender, etc.)\n",
    "same_val_cols = (\n",
    "    ['id', 'group'] + \n",
    "    list(dupes_only.columns[list(dupes_only.columns).index('education'):])\n",
    ")\n",
    "df = dupes_only.pivot(index=same_val_cols, columns='time')\n",
    "df.columns = df.columns.map(\n",
    "    lambda x: f'{x[0]}_{\"before\" if x[1] == 1 else \"after\"}'\n",
    ")\n",
    "df = df.reset_index()\n",
    "\n",
    "# deal with columns for data that wasn't collected in both sessions\n",
    "all_nan_cols = df.columns[df.isnull().sum(axis=0) == len(df)]\n",
    "df = df.drop(columns=all_nan_cols)\n",
    "for colname in all_nan_cols:\n",
    "    base_colname, _, suffix = colname.rpartition('_')\n",
    "    other_suffix = 'before' if suffix == 'after' else 'after'\n",
    "    df = df.rename(columns={f'{base_colname}_{other_suffix}': base_colname})\n",
    "    \n",
    "# add column for change in pain level\n",
    "# (this will be the response variable for the model)\n",
    "df['bpi_intensity_change'] = df['bpi_intensity_before'] - df['bpi_intensity_after']\n",
    "# display dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea5e09",
   "metadata": {},
   "source": [
    "# select a subset of variables to use as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bafce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.801226Z",
     "start_time": "2023-09-28T18:49:53.799088Z"
    }
   },
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'group', 'education', 'ethnicity', 'hispanic', 'employment_status', \n",
    "    'exercise', 'handedness', 'sses', 'married_or_living_as_marri', 'age', \n",
    "    'weight', 'gender', 'backpain_length'\n",
    "]\n",
    "X = df[predictors]\n",
    "y = df['bpi_intensity_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be5d7e",
   "metadata": {},
   "source": [
    "# fit the model and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3326fee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.804463Z",
     "start_time": "2023-09-28T18:49:53.802073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Linear Model\n",
      "===================\n",
      "Number of observations: 135\n",
      "Number of predictors: 14\n",
      "Model degrees of freedom: 13\n",
      "Error degrees of freedom: 121\n",
      "Residual standard error: 193.674\n",
      "R^2: 0.399\n",
      "AIC: 76.722\n",
      "\n",
      "Coefficients:\n",
      "-------------\n",
      "\u001b[1mName                            B̂      SE       t       p\u001b[0m\n",
      "Intercept                    5.284   1.641   3.220   0.002 \u001b[1m**\u001b[0m\n",
      "group                       -1.054   0.137  -7.670   0.000 \u001b[1m***\u001b[0m\n",
      "education                   -0.543   0.278  -1.955   0.053 \u001b[1m\u001b[0m\n",
      "ethnicity                    0.058   0.219   0.264   0.792 \u001b[1m\u001b[0m\n",
      "hispanic                    -0.373   0.716  -0.522   0.603 \u001b[1m\u001b[0m\n",
      "employment_status           -0.298   0.147  -2.019   0.046 \u001b[1m*\u001b[0m\n",
      "exercise                    -0.121   0.124  -0.975   0.331 \u001b[1m\u001b[0m\n",
      "handedness                   0.462   0.240   1.924   0.057 \u001b[1m\u001b[0m\n",
      "sses                        -0.047   0.068  -0.681   0.497 \u001b[1m\u001b[0m\n",
      "married_or_living_as_marri   0.119   0.254   0.466   0.642 \u001b[1m\u001b[0m\n",
      "age                          0.009   0.009   1.033   0.304 \u001b[1m\u001b[0m\n",
      "weight                      -0.003   0.004  -0.881   0.380 \u001b[1m\u001b[0m\n",
      "gender                       0.253   0.258   0.981   0.329 \u001b[1m\u001b[0m\n",
      "backpain_length             -0.018   0.014  -1.270   0.206 \u001b[1m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "glm = GLM(X, y).fit()\n",
    "glm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc875cd",
   "metadata": {},
   "source": [
    "# run some individual t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e82a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.807571Z",
     "start_time": "2023-09-28T18:49:53.805470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "\tt = -1.9546532038088111, p = 0.05293030529967579\n",
      "employment_status\n",
      "\tt = -2.0186211253690964, p = 0.04573738199608248\n"
     ]
    }
   ],
   "source": [
    "print('education')\n",
    "t, p = glm.t_test('education')\n",
    "print(f\"\\t{t = }, {p = }\")\n",
    "\n",
    "print('employment_status')\n",
    "t, p = glm.t_test('employment_status')\n",
    "print(f\"\\t{t = }, {p = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e8af8",
   "metadata": {},
   "source": [
    "# run some F-tests on a few subsets of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d2f527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.811494Z",
     "start_time": "2023-09-28T18:49:53.808504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept-only model\n",
      "\tF = 80.22027070929019, p = 4.903937633539385e-15\n",
      "\n",
      "[\"group\", \"employment_status\", \"age\"]\n",
      "\tF = 0.36459164573984326, p = 0.9733056577039912\n"
     ]
    }
   ],
   "source": [
    "print('intercept-only model')\n",
    "F, p = glm.f_test()\n",
    "print(f\"\\t{F = }, {p = }\\n\")\n",
    "\n",
    "print('[\"group\", \"employment_status\", \"age\"]')\n",
    "F, p = glm.f_test([\"employment_status\", \"age\"])\n",
    "print(f\"\\t{F = }, {p = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604ff8a",
   "metadata": {},
   "source": [
    "# test some contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fddb39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.816467Z",
     "start_time": "2023-09-28T18:49:53.813512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_vs_education = array([ 0,  1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "\tt = -1.7110376121312285, p = 0.0896365856306869\n",
      "\n",
      "ethnicity_vs_employment_status = array([ 0,  0,  0,  1,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "\tt = 1.382285772613835, p = 0.16943021507691455\n"
     ]
    }
   ],
   "source": [
    "group_vs_education = np.zeros(glm.n_predictors, dtype=int)\n",
    "group_vs_education[[1, 2]] = [1, -1]\n",
    "print(f\"{group_vs_education = }\")\n",
    "t, p = glm.test_contrast(group_vs_education)\n",
    "print(f\"\\t{t = }, {p = }\\n\")\n",
    "\n",
    "ethnicity_vs_employment_status = np.zeros(glm.n_predictors, dtype=int)\n",
    "ethnicity_vs_employment_status[[3, 5]] = [1, -1]\n",
    "print(f\"{ethnicity_vs_employment_status = }\")\n",
    "t, p = glm.test_contrast(ethnicity_vs_employment_status)\n",
    "print(f\"\\t{t = }, {p = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20650103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T08:25:48.798072Z",
     "start_time": "2023-09-28T08:25:48.789642Z"
    }
   },
   "source": [
    "# predict response variable for some (fake) new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5df0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:49:53.820106Z",
     "start_time": "2023-09-28T18:49:53.817612Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99317962, 0.11215594, 2.29967943])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "new_data = np.random.rand(3, glm.X_.shape[1])\n",
    "glm.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psyc178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}