{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c71d09",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a63bbe1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:55.749013Z",
     "start_time": "2023-09-28T09:17:55.280483Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import davos\n",
    "except ModuleNotFoundError:\n",
    "    %pip install davos\n",
    "    import davos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf60c5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.304340Z",
     "start_time": "2023-09-28T09:17:55.751699Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections.abc smuggle Iterable\n",
    "\n",
    "smuggle numpy as np                 # pip: numpy==1.26.0\n",
    "smuggle pandas as pd                # pip: pandas==2.1.1\n",
    "from scipy smuggle stats            # pip: scipy==1.11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd935da",
   "metadata": {},
   "source": [
    "# Implement a GLM from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ef5730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.309219Z",
     "start_time": "2023-09-28T09:17:56.307267Z"
    }
   },
   "outputs": [],
   "source": [
    "def requires_fit(method):\n",
    "    \"\"\"\n",
    "    Decorator used in GLM class to disallow running certain methods \n",
    "    before fitting the model.\n",
    "    \"\"\"\n",
    "    def check_fitted_wrapper(self, *args, **kwargs):\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\n",
    "                f\"Model must be fit before running self.{method.__name__}. \"\n",
    "                \"Fit the model first with self.fit()\"\n",
    "            )\n",
    "        return method(self, *args, **kwargs)\n",
    "    return check_fitted_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7347625",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.345974Z",
     "start_time": "2023-09-28T09:17:56.310145Z"
    }
   },
   "outputs": [],
   "source": [
    "class GLM:\n",
    "    def __init__(self, X, y, ensure_intercept=True, predictor_labels=None):\n",
    "        \"\"\"\n",
    "        Initialize a GLM instance to fit, inspect, and run tests.\n",
    "        Accepts a design matrix X and response vector y as lists/numpy\n",
    "        arrays or labeled pandas DataFrames/Series.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Design matrix with shape (n, p). `n` is the number of\n",
    "            observations and `p` is the number of predictors, optionally\n",
    "            including an intercept (see `ensure_intercept` below).\n",
    "            If X is a pandas DataFrame, column names will be used as\n",
    "            labels for the predictor variables.\n",
    "        y : array-like\n",
    "            Response vector with shape (n,).\n",
    "        ensure_intercept : bool, optional\n",
    "            If True (default), ensure that the first column of X\n",
    "            contains all 1's for the intercept, inserting one if\n",
    "            necessary. If False, do not include an intercept.\n",
    "        predictor_labels : list of str, optional\n",
    "            List of labels for the predictors in X. If None (default),\n",
    "            use column names from X if X is a pandas DataFrame,\n",
    "            otherwise use generic labels \"X_0\", \"X_1\", etc.\n",
    "        \"\"\"\n",
    "        if predictor_labels is None:\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                self.predictor_labels = X.columns.tolist()\n",
    "            elif isinstance(X, pd.Series):\n",
    "                self.predictor_labels = X.index.tolist()\n",
    "            else:\n",
    "                self.predictor_labels = [f\"X_{i}\" for i in range(X.shape[1])]\n",
    "        elif not isinstance(predictor_labels, Iterable):\n",
    "            raise TypeError(\"'predictor_labels' must be an iterable if passed\")\n",
    "        elif len(predictor_labels) != X.shape[1]:\n",
    "            raise ValueError(\n",
    "                f\"'predictor_labels' must contain {X.shape[1]} labels\"\n",
    "            )\n",
    "        else:\n",
    "            self.predictor_labels = predictor_labels\n",
    "\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y).squeeze()\n",
    "\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\n",
    "                \"X and y must have the same number of rows (observations)\"\n",
    "            )\n",
    "        if y.ndim != 1:\n",
    "            raise ValueError(\"y must be a n x 1 vector of observed responses\")\n",
    "\n",
    "        if ensure_intercept and not (X[:, 0] == 1).all():\n",
    "            self.X_ = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "            self.predictor_labels.insert(0, \"Intercept\")\n",
    "        else:\n",
    "            self.X_ = X\n",
    "\n",
    "        self.y_ = y\n",
    "        self.n_obs = X.shape[0]\n",
    "        self.n_predictors = self.X_.shape[1]    # p includes intercept\n",
    "        self.df_model = self.n_predictors - 1\n",
    "        self.df_error = self.n_obs - self.n_predictors\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fit the model with the data provided at initialization. Both\n",
    "        returns the fitted model and updates it in place (a la\n",
    "        scikit-learn estimators).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        GLM\n",
    "            The fitted GLM instance\n",
    "        \"\"\"\n",
    "        gram_inv = np.linalg.inv(self.X_.T @ self.X_)\n",
    "        # beta-hat, shape: (self.n_predictors,)\n",
    "        self.betas = gram_inv @ self.X_.T @ self.y_\n",
    "        # y-hat, shape: (self.n_obs,)\n",
    "        # also alias y_hat as y_pred (standard scikit-learn convention)\n",
    "        self.y_hat = self.y_pred = self.X_ @ self.betas\n",
    "        # residuals, shape: (self.n_obs,)\n",
    "        self.residuals = self.y_ - self.y_hat\n",
    "        self.ss_res = (self.residuals ** 2).sum()\n",
    "        self.ss_tot = ((self.y_ - self.y_.mean()) ** 2).sum()\n",
    "        self.R2 = 1 - self.ss_res / self.ss_tot\n",
    "        self.AIC = self.n_obs * np.log(self.ss_res / self.n_obs) + 2 * self.n_predictors\n",
    "        # variance/covariance matrix for betas,\n",
    "        # shape: (self.n_predictors, self.n_predictors)\n",
    "        self.beta_cov = self.ss_res / self.df_error * gram_inv\n",
    "        # standard errors for betas, shape: (self.n_predictors,)\n",
    "        self.beta_ses = np.diag(self.beta_cov) ** 0.5\n",
    "        # t-statistics for betas, shape: (self.n_predictors,)\n",
    "        self.beta_ts = self.betas / self.beta_ses\n",
    "        # (2-tailed) p-values for t-tests for betas,\n",
    "        # shape: (self.n_predictors,)\n",
    "        self.beta_ps = 2 * stats.t.sf(np.abs(self.beta_ts), self.df_error)\n",
    "        # set fitted flag to True to enable other methods that require\n",
    "        # these computations first\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    @requires_fit\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the value of the response variable for new data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Array containing with the same number of predictors as the\n",
    "            design matrix used to fit the model. May contain any number\n",
    "            of observations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : 1D array\n",
    "            Predicted values of the response variable for each row of X.\n",
    "\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(np.asarray(X))\n",
    "        if X.shape[1] != self.n_predictors:\n",
    "            raise ValueError(\n",
    "                f\"X must have {self.n_predictors} columns (predictors)\"\n",
    "            )\n",
    "        return X @ self.betas\n",
    "\n",
    "    @requires_fit\n",
    "    def summary(self):\n",
    "        \"\"\"Print a formatted summary table of model results.\"\"\"\n",
    "        print(\"General Linear Model\")\n",
    "        print(\"===================\")\n",
    "        print(f\"Number of observations: {self.n_obs}\")\n",
    "        print(f\"Number of predictors: {self.n_predictors}\")\n",
    "        print(f\"Model degrees of freedom: {self.df_model}\")\n",
    "        print(f\"Error degrees of freedom: {self.df_error}\")\n",
    "        print(f\"Residual standard error: {self.ss_res:.3f}\")\n",
    "        print(f\"R^2: {self.R2:.3f}\")\n",
    "        print(f\"AIC: {self.AIC:.3f}\")\n",
    "        print(\"\\nCoefficients:\")\n",
    "        print(\"-------------\")\n",
    "        # Format the table width to fit the longest predictor name\n",
    "        # (min width: 4 cols)\n",
    "        name_col_width = max(len(max(self.predictor_labels, key=len)), 4)\n",
    "        header = \"\\033[1m{:<{width}}{:>8}{:>8}{:>8}{:>8}\\033[0m\".format(\n",
    "            \"Name\", \"B̂\", \"SE\", \"t\", \"p\", width=name_col_width\n",
    "        )\n",
    "        print(header)\n",
    "        for i in range(self.n_predictors):\n",
    "            label = self.predictor_labels[i]\n",
    "            beta = self.betas[i]\n",
    "            se = self.beta_ses[i]\n",
    "            t = self.beta_ts[i]\n",
    "            p = self.beta_ps[i]\n",
    "            if p < 0.001:\n",
    "                sig = '***'\n",
    "            elif p < 0.01:\n",
    "                sig = '**'\n",
    "            elif p < 0.05:\n",
    "                sig = '*'\n",
    "            else:\n",
    "                sig = ''\n",
    "            print(\"{:<{width}}{:>8.3f}{:>8.3f}{:>8.3f}{:>8.3f} \\033[1m{sig}\\033[0m\".format(\n",
    "                label, beta, se, t, p, width=name_col_width, sig=sig)\n",
    "            )\n",
    "\n",
    "    @requires_fit\n",
    "    def t_test(self, predictor):\n",
    "        \"\"\"\n",
    "        Two-tailed t-test for the null hypothesis that the estimated\n",
    "        coefficient for a given predictor is not significantly\n",
    "        different from zero.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictor : int or str\n",
    "            Index or label of predictor for which to run the t-test.\n",
    "            Note that the 0th predictor refers to the intercept.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t, p\n",
    "            t-statistic and associated p-value as a tuple.\n",
    "        \"\"\"\n",
    "        if isinstance(predictor, str):\n",
    "            predictor = self.predictor_labels.index(predictor)\n",
    "        elif not isinstance(predictor, int):\n",
    "            raise TypeError(\"'predictor' must be an int or str\")\n",
    "        return self.beta_ts[predictor], self.beta_ps[predictor]\n",
    "\n",
    "    @requires_fit\n",
    "    def test_contrast(self, contrast):\n",
    "        \"\"\"\n",
    "        Two-tailed t-test for the null hypothesis that the given\n",
    "        contrast of predictors is not significantly different from zero.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        contrast : array-like\n",
    "            Contrast vector of shape (p,). p is the number of predictors\n",
    "            (including the intercept).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        t, p\n",
    "            t-statistic and associated p-value as a tuple.\n",
    "        \"\"\"\n",
    "        contrast = np.asarray(contrast).squeeze()\n",
    "        if contrast.ndim != 1:\n",
    "            raise ValueError(\"'contrast' must be a 1D array\")\n",
    "        if contrast.shape[0] != self.n_predictors:\n",
    "            raise ValueError(\n",
    "                f\"'contrast' must have {self.n_predictors} elements\"\n",
    "            )\n",
    "        # compute t-statistic\n",
    "        # note: contrast matrices not transposed here because numpy\n",
    "        # automatically does so for 1D vectors\n",
    "        t_stat = (\n",
    "                (contrast @ self.betas) /\n",
    "                np.sqrt(contrast @ self.beta_cov @ contrast)\n",
    "        )\n",
    "        # compute (2-tailed) p-value\n",
    "        p_value = 2 * stats.t.sf(np.abs(t_stat), self.df_error)\n",
    "        return t_stat, p_value\n",
    "\n",
    "    @requires_fit\n",
    "    def f_test(self, predictors=None):\n",
    "        \"\"\"\n",
    "        F-test for the null hypothesis that the given (set of)\n",
    "        predictor(s) has no effect on the response variable (i.e., that\n",
    "        the quality of the model fit would not significantly worsen if\n",
    "        the given predictor(s) were removed).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictors : int, str, or iterable of int or str, optional\n",
    "            index/indices or label(s) of predictor(s) for which to run\n",
    "            the F-test. Note that the 0th predictor refers to the\n",
    "            intercept. If None (default), the F-test is run on all\n",
    "            predictors (i.e., an intercept-only model).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        F, p: tuple of float\n",
    "            F-statistic and associated p-value as a tuple.\n",
    "        \"\"\"\n",
    "        if predictors is None:\n",
    "            predictors = [0]\n",
    "        elif isinstance(predictors, int):\n",
    "            predictors = [predictors]\n",
    "        elif isinstance(predictors, str):\n",
    "            predictors = [self.predictor_labels.index(predictors)]\n",
    "        elif isinstance(predictors, Iterable):\n",
    "            _predictors = []\n",
    "            for p in predictors:\n",
    "                if isinstance(p, str):\n",
    "                    _predictors.append(self.predictor_labels.index(p))\n",
    "                elif isinstance(p, int):\n",
    "                    _predictors.append(p)\n",
    "                else:\n",
    "                    raise TypeError(\n",
    "                        \"'predictors' must be an int, str, or iterable of int \"\n",
    "                        \"or str\"\n",
    "                    )\n",
    "            predictors = _predictors\n",
    "        if not all(p in range(self.n_predictors) for p in predictors):\n",
    "            raise ValueError(\"'predictors' must be a valid predictor index or \"\n",
    "                             \"label\"\n",
    "                             )\n",
    "        if len(predictors) == 0:\n",
    "            raise ValueError(\"'predictors' must contain at least one index or \"\n",
    "                             \"label\"\n",
    "                             )\n",
    "        # get sum of squared residuals for reduced model\n",
    "        X_reduced = np.delete(self.X_, predictors, axis=1)\n",
    "        betas_reduced = np.linalg.inv(X_reduced.T @ X_reduced) @ X_reduced.T @ self.y_\n",
    "        residuals_reduced = self.y_ - X_reduced @ betas_reduced\n",
    "        ssr_reduced = (residuals_reduced ** 2).sum()\n",
    "        # compute F-statistic\n",
    "        ssr_full = self.ss_res\n",
    "        p = self.n_predictors\n",
    "        q = len(predictors)\n",
    "        n = self.n_obs\n",
    "        f_stat = ((ssr_reduced - ssr_full) / (p - q)) / (ssr_full / (n - p))\n",
    "        # compute p-value\n",
    "        p_value = 1 - stats.f.sf(f_stat, p - q, n - p)\n",
    "        return f_stat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b2435",
   "metadata": {},
   "source": [
    "# Load in (and clean) some data to test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927a48fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.883097Z",
     "start_time": "2023-09-28T09:17:56.346998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>exercise</th>\n",
       "      <th>handedness</th>\n",
       "      <th>sses</th>\n",
       "      <th>married_or_living_as_marri</th>\n",
       "      <th>...</th>\n",
       "      <th>sopa_emo_after</th>\n",
       "      <th>pgic</th>\n",
       "      <th>tx_satisfaction</th>\n",
       "      <th>alcohol_before</th>\n",
       "      <th>alcohol_after</th>\n",
       "      <th>opioid_before</th>\n",
       "      <th>opioid_after</th>\n",
       "      <th>cannabis_before</th>\n",
       "      <th>cannabis_after</th>\n",
       "      <th>bpi_intensity_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1268</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1277</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>1294</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1302</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  group  education  ethnicity  hispanic  employment_status  exercise  \\\n",
       "0      12    3.0        2.0        4.0       0.0                1.0       3.0   \n",
       "1      14    3.0        3.0        4.0       0.0                3.0       4.0   \n",
       "2      15    3.0        2.0        5.0       0.0                1.0       3.0   \n",
       "3      18    2.0        3.0        4.0       0.0                1.0       3.0   \n",
       "4      23    2.0        3.0        2.0       0.0                1.0       5.0   \n",
       "..    ...    ...        ...        ...       ...                ...       ...   \n",
       "130  1268    2.0        3.0        4.0       0.0                2.0       4.0   \n",
       "131  1277    2.0        3.0        4.0       0.0                1.0       3.0   \n",
       "132  1294    2.0        3.0        4.0       0.0                1.0       3.0   \n",
       "133  1302    3.0        3.0        4.0       0.0                1.0       2.0   \n",
       "134  1319    2.0        3.0        5.0       0.0                1.0       3.0   \n",
       "\n",
       "     handedness  sses  married_or_living_as_marri  ...  sopa_emo_after  pgic  \\\n",
       "0           1.0   4.0                         0.0  ...             8.0   1.0   \n",
       "1           1.0   9.0                         0.0  ...             6.0   1.0   \n",
       "2           1.0   6.0                         1.0  ...             4.0   1.0   \n",
       "3           1.0   5.0                         1.0  ...             9.0   5.0   \n",
       "4           1.0   6.0                         0.0  ...             8.0   1.0   \n",
       "..          ...   ...                         ...  ...             ...   ...   \n",
       "130         1.0   8.0                         1.0  ...             8.0   5.0   \n",
       "131         1.0   8.0                         1.0  ...            10.0   5.0   \n",
       "132         1.0   6.0                         0.0  ...             8.0   2.0   \n",
       "133         1.0   8.0                         0.0  ...             6.0   2.0   \n",
       "134         1.0   5.0                         0.0  ...             5.0   5.0   \n",
       "\n",
       "     tx_satisfaction  alcohol_before  alcohol_after  opioid_before  \\\n",
       "0               52.0             0.0            0.0            0.0   \n",
       "1               30.5            23.0           21.0            0.0   \n",
       "2               50.5            15.0           29.0            0.0   \n",
       "3               50.0             0.0            2.0            0.0   \n",
       "4               17.5            29.0           13.5            0.0   \n",
       "..               ...             ...            ...            ...   \n",
       "130             88.0             2.0            1.0            0.0   \n",
       "131             46.0            23.0           30.0            0.0   \n",
       "132             54.0             0.0            0.0            0.0   \n",
       "133             64.0             3.0            3.0            0.0   \n",
       "134             69.0            11.0            3.0            2.0   \n",
       "\n",
       "     opioid_after  cannabis_before  cannabis_after  bpi_intensity_change  \n",
       "0             0.0            2.000           0.000                 -0.25  \n",
       "1             0.0            3.500           3.500                  0.50  \n",
       "2             0.0            0.000           0.000                 -0.50  \n",
       "3             0.0            0.000           0.000                  2.25  \n",
       "4             0.0            0.015           0.025                  0.25  \n",
       "..            ...              ...             ...                   ...  \n",
       "130           0.0            0.000           0.000                  1.75  \n",
       "131           0.0            0.000           0.000                 -0.75  \n",
       "132           0.0            0.000           0.000                  0.00  \n",
       "133           0.0            0.000           0.000                  0.00  \n",
       "134           1.0            7.000          19.000                  0.75  \n",
       "\n",
       "[135 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset from GitHub\n",
    "dataset_url = (\n",
    "    \"https://github.com/torwager/ComputationalFoundations/raw/\"\n",
    "    \"79b92a3/CompFound/datasets/Ashar2022_outcomes_demographics.csv\"\n",
    ")\n",
    "df_raw = pd.read_csv(dataset_url, na_values={'current_opioid_use': '<undefined>'})\n",
    "\n",
    "# drop individuals that don't have data for both sessions\n",
    "dupes_only = df_raw.loc[df_raw.duplicated('id', keep=False)]\n",
    "\n",
    "# make sure each individual's data actually comes from 2 different \n",
    "# sessions (i.e., no duplicates or mislabels)\n",
    "for i in dupes_only['id'].unique():\n",
    "    assert set(dupes_only.query('id == @i')['time']) == {1, 2}\n",
    "\n",
    "# reshape to have one row per participant with data from both sessions\n",
    "# pivot on columns with session-agnostic values (age, gender, etc.)\n",
    "same_val_cols = (\n",
    "    ['id', 'group'] + \n",
    "    list(dupes_only.columns[list(dupes_only.columns).index('education'):])\n",
    ")\n",
    "df = dupes_only.pivot(index=same_val_cols, columns='time')\n",
    "df.columns = df.columns.map(\n",
    "    lambda x: f'{x[0]}_{\"before\" if x[1] == 1 else \"after\"}'\n",
    ")\n",
    "df = df.reset_index()\n",
    "\n",
    "# deal with columns for data that wasn't collected in both sessions\n",
    "all_nan_cols = df.columns[df.isnull().sum(axis=0) == len(df)]\n",
    "df = df.drop(columns=all_nan_cols)\n",
    "for colname in all_nan_cols:\n",
    "    base_colname, _, suffix = colname.rpartition('_')\n",
    "    other_suffix = 'before' if suffix == 'after' else 'after'\n",
    "    df = df.rename(columns={f'{base_colname}_{other_suffix}': base_colname})\n",
    "    \n",
    "# add column for change in pain level\n",
    "# (this will be the response variable for the model)\n",
    "df['bpi_intensity_change'] = df['bpi_intensity_before'] - df['bpi_intensity_after']\n",
    "# display dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea5e09",
   "metadata": {},
   "source": [
    "# select a subset of variables to use as predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bafce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.885919Z",
     "start_time": "2023-09-28T09:17:56.884056Z"
    }
   },
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    'group', 'education', 'ethnicity', 'hispanic', 'employment_status', \n",
    "    'exercise', 'handedness', 'sses', 'married_or_living_as_marri', 'age', \n",
    "    'weight', 'gender', 'backpain_length'\n",
    "]\n",
    "X = df[predictors]\n",
    "y = df['bpi_intensity_change']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83be5d7e",
   "metadata": {},
   "source": [
    "# fit the model and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3326fee8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.889059Z",
     "start_time": "2023-09-28T09:17:56.886728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Linear Model\n",
      "===================\n",
      "Number of observations: 135\n",
      "Number of predictors: 14\n",
      "Model degrees of freedom: 13\n",
      "Error degrees of freedom: 121\n",
      "Residual standard error: 193.674\n",
      "R^2: 0.399\n",
      "AIC: 76.722\n",
      "\n",
      "Coefficients:\n",
      "-------------\n",
      "\u001b[1mName                            B̂      SE       t       p\u001b[0m\n",
      "Intercept                    5.284   1.641   3.220   0.002 \u001b[1m**\u001b[0m\n",
      "group                       -1.054   0.137  -7.670   0.000 \u001b[1m***\u001b[0m\n",
      "education                   -0.543   0.278  -1.955   0.053 \u001b[1m\u001b[0m\n",
      "ethnicity                    0.058   0.219   0.264   0.792 \u001b[1m\u001b[0m\n",
      "hispanic                    -0.373   0.716  -0.522   0.603 \u001b[1m\u001b[0m\n",
      "employment_status           -0.298   0.147  -2.019   0.046 \u001b[1m*\u001b[0m\n",
      "exercise                    -0.121   0.124  -0.975   0.331 \u001b[1m\u001b[0m\n",
      "handedness                   0.462   0.240   1.924   0.057 \u001b[1m\u001b[0m\n",
      "sses                        -0.047   0.068  -0.681   0.497 \u001b[1m\u001b[0m\n",
      "married_or_living_as_marri   0.119   0.254   0.466   0.642 \u001b[1m\u001b[0m\n",
      "age                          0.009   0.009   1.033   0.304 \u001b[1m\u001b[0m\n",
      "weight                      -0.003   0.004  -0.881   0.380 \u001b[1m\u001b[0m\n",
      "gender                       0.253   0.258   0.981   0.329 \u001b[1m\u001b[0m\n",
      "backpain_length             -0.018   0.014  -1.270   0.206 \u001b[1m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "glm = GLM(X, y).fit()\n",
    "glm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc875cd",
   "metadata": {},
   "source": [
    "# run some individual t-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e82a93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.891882Z",
     "start_time": "2023-09-28T09:17:56.889866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "\tt = -1.9546532038088111, p = 0.05293030529967579\n",
      "employment_status\n",
      "\tt = -2.0186211253690964, p = 0.04573738199608248\n"
     ]
    }
   ],
   "source": [
    "print('education')\n",
    "t, p = glm.t_test('education')\n",
    "print(f\"\\t{t = }, {p = }\")\n",
    "\n",
    "print('employment_status')\n",
    "t, p = glm.t_test('employment_status')\n",
    "print(f\"\\t{t = }, {p = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e8af8",
   "metadata": {},
   "source": [
    "# run some F-tests on a few subsets of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d2f527",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.896202Z",
     "start_time": "2023-09-28T09:17:56.893673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept-only model\n",
      "\tF = 0.7973615043633908, p = 0.33822917792098983\n",
      "\n",
      "[\"group\", \"employment_status\", \"age\"]\n",
      "\tF = 0.36459164573984326, p = 0.026694342296008755\n"
     ]
    }
   ],
   "source": [
    "print('intercept-only model')\n",
    "F, p = glm.f_test()\n",
    "print(f\"\\t{F = }, {p = }\\n\")\n",
    "\n",
    "print('[\"group\", \"employment_status\", \"age\"]')\n",
    "F, p = glm.f_test([\"employment_status\", \"age\"])\n",
    "print(f\"\\t{F = }, {p = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604ff8a",
   "metadata": {},
   "source": [
    "# test some contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fddb39a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.900586Z",
     "start_time": "2023-09-28T09:17:56.897312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group_vs_education = array([ 0,  1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "\tt = -1.7110376121312285, p = 0.0896365856306869\n",
      "\n",
      "ethnicity_vs_employment_status = array([ 0,  0,  0,  1,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0])\n",
      "\tt = 1.382285772613835, p = 0.16943021507691455\n"
     ]
    }
   ],
   "source": [
    "group_vs_education = np.zeros(glm.n_predictors, dtype=int)\n",
    "group_vs_education[[1, 2]] = [1, -1]\n",
    "print(f\"{group_vs_education = }\")\n",
    "t, p = glm.test_contrast(group_vs_education)\n",
    "print(f\"\\t{t = }, {p = }\\n\")\n",
    "\n",
    "ethnicity_vs_employment_status = np.zeros(glm.n_predictors, dtype=int)\n",
    "ethnicity_vs_employment_status[[3, 5]] = [1, -1]\n",
    "print(f\"{ethnicity_vs_employment_status = }\")\n",
    "t, p = glm.test_contrast(ethnicity_vs_employment_status)\n",
    "print(f\"\\t{t = }, {p = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20650103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T08:25:48.798072Z",
     "start_time": "2023-09-28T08:25:48.789642Z"
    }
   },
   "source": [
    "# predict response variable for some (fake) new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5df0fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T09:17:56.904533Z",
     "start_time": "2023-09-28T09:17:56.901577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.99317962, 0.11215594, 2.29967943])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "new_data = np.random.rand(3, glm.X_.shape[1])\n",
    "glm.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psyc178",
   "language": "python",
   "name": "psyc178"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
